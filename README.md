# BodyMaps SuPreM Segmentation Demo

A web-based application for AI-powered medical image segmentation using the SuPreM model. This demo allows users to upload CT scans in NIfTI format (.nii.gz) and receive automated organ segmentation results.

**Developed for Johns Hopkins CCVL Lab - Project II Application**

## ğŸš€ Features

- **Easy Upload**: Drag & drop interface for .nii.gz CT scan files
- **AI Processing**: Automated segmentation using SuPreM AI model in Docker
- **Real-time Status**: Live updates during processing
- **Visual Results**: Preview segmented organs with interactive image viewer
- **Download Results**: Complete segmentation files in ZIP format
- **Responsive Design**: Bootstrap-based UI that works on desktop and mobile

## ğŸ›  Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Backend** | Flask (Python) | Web server, file handling, Docker integration |
| **Frontend** | HTML5 + Bootstrap 5 + JavaScript | User interface and interactions |
| **AI Engine** | SuPreM model via Docker | Medical image segmentation |
| **Image Processing** | nibabel + matplotlib | NIfTI file handling and visualization |
| **Storage** | Local filesystem | Temporary file storage |

## ğŸ“‹ Prerequisites

Before running this application, ensure you have:

1. **Python 3.8+** with pip
2. **Docker** installed and running
3. **SuPreM Docker image** (qchen99/suprem:v1)

### Installing Docker and SuPreM Model

```bash
# Install Docker (macOS with Homebrew)
brew install docker

# Start Docker Desktop
open -a Docker

# Pull the SuPreM model (this may take some time - ~5GB)
docker pull qchen99/suprem:v1

# Verify the image is available
docker images | grep suprem
```

## ğŸ”§ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/sshhaawwnn111/BodyMaps-Demo.git
cd BodyMaps-Demo
```

### 2. Create Virtual Environment

```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# On macOS/Linux:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Create Required Directories

```bash
mkdir -p inputs_data outputs_data static/results
```

### 5. Run the Application

```bash
python app.py
```

The application will start on `http://localhost:5000`

## ğŸ“ Project Structure

```
BodyMaps-Demo/
â”‚
â”œâ”€â”€ app.py                      # Main Flask application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ templates/                  # HTML templates
â”‚   â”œâ”€â”€ upload.html            # Main upload interface
â”‚   â””â”€â”€ results.html           # Results display page
â”‚
â”œâ”€â”€ utils/                      # Utility functions
â”‚   â””â”€â”€ nii_to_png.py          # NIfTI to PNG conversion
â”‚
â”œâ”€â”€ static/                     # Static files
â”‚   â””â”€â”€ results/               # Generated preview images
â”‚       â””â”€â”€ casename00001/     # Results for each case
â”‚
â”œâ”€â”€ inputs_data/               # Uploaded CT scans
â”‚   â””â”€â”€ casename00001/         # Auto-generated case directories
â”‚       â””â”€â”€ ct.nii.gz         # Uploaded CT scan
â”‚
â””â”€â”€ outputs_data/              # SuPreM segmentation results
    â””â”€â”€ casename00001/         # Results for each case
        â””â”€â”€ segmentations/     # Segmented organ files
            â”œâ”€â”€ liver.nii.gz
            â”œâ”€â”€ kidney_left.nii.gz
            â”œâ”€â”€ kidney_right.nii.gz
            â””â”€â”€ combined_labels.nii.gz
```

## ğŸ“„ License

This project is developed for educational and demonstration purposes as part of the Johns Hopkins CCVL Lab application process.

## ğŸ“ Contact

**Developer**: Shawn Wang  
**Purpose**: Johns Hopkins CCVL Lab - Project II Application  
**Date**: July 2025

---

**Note**: This is a prototype demonstration application. For production use, additional security measures, error handling, and performance optimizations would be required.